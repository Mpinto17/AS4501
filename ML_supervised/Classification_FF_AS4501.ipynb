{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Basics:-overfitting,-underfitting-and-the-bias-variance-trade-off\" data-toc-modified-id=\"Basics:-overfitting,-underfitting-and-the-bias-variance-trade-off-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Basics: overfitting, underfitting and the bias-variance trade-off</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bias\" data-toc-modified-id=\"Bias-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Bias</a></span></li><li><span><a href=\"#Variance\" data-toc-modified-id=\"Variance-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Variance</a></span></li><li><span><a href=\"#Complexity,-accuracy,-robustness\" data-toc-modified-id=\"Complexity,-accuracy,-robustness-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Complexity, accuracy, robustness</a></span></li><li><span><a href=\"#Model-selection\" data-toc-modified-id=\"Model-selection-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Model selection</a></span></li></ul></li><li><span><a href=\"#Types-of-machine-learning\" data-toc-modified-id=\"Types-of-machine-learning-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Types of machine learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predictive-or-supervised-learning:\" data-toc-modified-id=\"Predictive-or-supervised-learning:-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Predictive or <strong>supervised learning</strong>:</a></span><ul class=\"toc-item\"><li><span><a href=\"#When-$y$-is-categorical-the-problem-is-known-as-classification.\" data-toc-modified-id=\"When-$y$-is-categorical-the-problem-is-known-as-classification.-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>When $y$ is <strong>categorical</strong> the problem is known as <strong>classification</strong>.</a></span></li><li><span><a href=\"#When-$y$-is-real--valued-the-problem-is-known-as-regression.\" data-toc-modified-id=\"When-$y$-is-real--valued-the-problem-is-known-as-regression.-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>When $y$ is <strong>real--valued</strong> the problem is known as <strong>regression</strong>.</a></span></li><li><span><a href=\"#Example-training-set:-the-iris-data-set\" data-toc-modified-id=\"Example-training-set:-the-iris-data-set-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Example training set: the iris data set</a></span></li></ul></li><li><span><a href=\"#Descriptive-or-unsupervised-learning\" data-toc-modified-id=\"Descriptive-or-unsupervised-learning-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Descriptive or <strong>unsupervised learning</strong></a></span></li><li><span><a href=\"#Reinforcement-learning\" data-toc-modified-id=\"Reinforcement-learning-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Reinforcement learning</a></span></li></ul></li><li><span><a href=\"#Metrics-and-diagnostics\" data-toc-modified-id=\"Metrics-and-diagnostics-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Metrics and diagnostics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Supervised-classification-loss\" data-toc-modified-id=\"Supervised-classification-loss-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Supervised classification loss</a></span></li><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#Types-of-errors\" data-toc-modified-id=\"Types-of-errors-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Types of errors</a></span></li><li><span><a href=\"#Completeness-and-contamination\" data-toc-modified-id=\"Completeness-and-contamination-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Completeness and contamination</a></span></li><li><span><a href=\"#Recall-and-precision\" data-toc-modified-id=\"Recall-and-precision-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Recall and precision</a></span></li><li><span><a href=\"#True-positive-rate-(TPR)-and-false-positive-rate-(FPR)\" data-toc-modified-id=\"True-positive-rate-(TPR)-and-false-positive-rate-(FPR)-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>True positive rate (TPR) and false positive rate (FPR)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Problems-with-the-accuracy\" data-toc-modified-id=\"Problems-with-the-accuracy-4.6.1\"><span class=\"toc-item-num\">4.6.1&nbsp;&nbsp;</span>Problems with the accuracy</a></span></li><li><span><a href=\"#Precision-and-recall-are-better\" data-toc-modified-id=\"Precision-and-recall-are-better-4.6.2\"><span class=\"toc-item-num\">4.6.2&nbsp;&nbsp;</span>Precision and recall are better</a></span></li></ul></li><li><span><a href=\"#F1-score\" data-toc-modified-id=\"F1-score-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>F1 score</a></span></li><li><span><a href=\"#F$_\\beta$-score\" data-toc-modified-id=\"F$_\\beta$-score-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>F$_\\beta$ score</a></span></li><li><span><a href=\"#Macro-vs-micro-averages\" data-toc-modified-id=\"Macro-vs-micro-averages-4.9\"><span class=\"toc-item-num\">4.9&nbsp;&nbsp;</span>Macro vs micro averages</a></span></li><li><span><a href=\"#Confusion-matrix\" data-toc-modified-id=\"Confusion-matrix-4.10\"><span class=\"toc-item-num\">4.10&nbsp;&nbsp;</span>Confusion matrix</a></span></li><li><span><a href=\"#Receiver-operating-characteristics-(ROC)-curve\" data-toc-modified-id=\"Receiver-operating-characteristics-(ROC)-curve-4.11\"><span class=\"toc-item-num\">4.11&nbsp;&nbsp;</span>Receiver operating characteristics (ROC) curve</a></span><ul class=\"toc-item\"><li><span><a href=\"#Area-under-the-curve-(AUC)-and-Gini-coefficient-(G1)\" data-toc-modified-id=\"Area-under-the-curve-(AUC)-and-Gini-coefficient-(G1)-4.11.1\"><span class=\"toc-item-num\">4.11.1&nbsp;&nbsp;</span>Area under the curve (AUC) and Gini coefficient (G1)</a></span></li></ul></li><li><span><a href=\"#Detection-Error-Tradeoff-(DET)-curve\" data-toc-modified-id=\"Detection-Error-Tradeoff-(DET)-curve-4.12\"><span class=\"toc-item-num\">4.12&nbsp;&nbsp;</span>Detection Error Tradeoff (DET) curve</a></span></li><li><span><a href=\"#scikit-learn-classification-metrics\" data-toc-modified-id=\"scikit-learn-classification-metrics-4.13\"><span class=\"toc-item-num\">4.13&nbsp;&nbsp;</span>scikit learn classification metrics</a></span></li></ul></li><li><span><a href=\"#Types-of-classifiers\" data-toc-modified-id=\"Types-of-classifiers-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Types of classifiers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scikit-Learn-API\" data-toc-modified-id=\"Scikit-Learn-API-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Scikit-Learn API</a></span></li></ul></li><li><span><a href=\"#Two-class-classification-examples\" data-toc-modified-id=\"Two-class-classification-examples-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Two class classification examples</a></span><ul class=\"toc-item\"><li><span><a href=\"#Two-classes,-one-feature-classification-example\" data-toc-modified-id=\"Two-classes,-one-feature-classification-example-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Two classes, one feature classification example</a></span></li><li><span><a href=\"#Two-class-classification-examples-from-sklearn\" data-toc-modified-id=\"Two-class-classification-examples-from-sklearn-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Two class classification examples from sklearn</a></span></li></ul></li><li><span><a href=\"#Multiclass-classification\" data-toc-modified-id=\"Multiclass-classification-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Multiclass classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-to-multiclass\" data-toc-modified-id=\"Binary-to-multiclass-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Binary to multiclass</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-vs-the-rest\" data-toc-modified-id=\"One-vs-the-rest-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>One vs the rest</a></span></li><li><span><a href=\"#One-vs-one\" data-toc-modified-id=\"One-vs-one-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>One vs one</a></span></li><li><span><a href=\"#Error-correcting-output-codes\" data-toc-modified-id=\"Error-correcting-output-codes-7.1.3\"><span class=\"toc-item-num\">7.1.3&nbsp;&nbsp;</span>Error correcting output codes</a></span></li></ul></li><li><span><a href=\"#Examples-of-multiclass-classification\" data-toc-modified-id=\"Examples-of-multiclass-classification-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Examples of multiclass classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiclass-classification-on-the-NIST-dataset\" data-toc-modified-id=\"Multiclass-classification-on-the-NIST-dataset-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Multiclass classification on the NIST dataset</a></span></li><li><span><a href=\"#Multiclass-classification-on-the-iris-dataset\" data-toc-modified-id=\"Multiclass-classification-on-the-iris-dataset-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Multiclass classification on the iris dataset</a></span></li></ul></li></ul></li><li><span><a href=\"#Training,-validation-and-test-sets\" data-toc-modified-id=\"Training,-validation-and-test-sets-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Training, validation and test sets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Cross-validation</a></span></li><li><span><a href=\"#Variations-on-k-fold\" data-toc-modified-id=\"Variations-on-k-fold-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Variations on k-fold</a></span><ul class=\"toc-item\"><li><span><a href=\"#repeated-k-fold\" data-toc-modified-id=\"repeated-k-fold-8.2.1\"><span class=\"toc-item-num\">8.2.1&nbsp;&nbsp;</span>repeated k-fold</a></span></li><li><span><a href=\"#Leave-one-out\" data-toc-modified-id=\"Leave-one-out-8.2.2\"><span class=\"toc-item-num\">8.2.2&nbsp;&nbsp;</span>Leave one out</a></span></li><li><span><a href=\"#Shuffle-&amp;-split\" data-toc-modified-id=\"Shuffle-&amp;-split-8.2.3\"><span class=\"toc-item-num\">8.2.3&nbsp;&nbsp;</span>Shuffle &amp; split</a></span></li></ul></li><li><span><a href=\"#Variations-on-k-fold-that-balance-(stratify)-class-labels\" data-toc-modified-id=\"Variations-on-k-fold-that-balance-(stratify)-class-labels-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Variations on k-fold that balance (stratify) class labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stratified-k-fold-CV\" data-toc-modified-id=\"Stratified-k-fold-CV-8.3.1\"><span class=\"toc-item-num\">8.3.1&nbsp;&nbsp;</span>Stratified k-fold CV</a></span></li></ul></li></ul></li><li><span><a href=\"#Unbalanced-classification\" data-toc-modified-id=\"Unbalanced-classification-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Unbalanced classification</a></span></li><li><span><a href=\"#Finding-hyperparameters\" data-toc-modified-id=\"Finding-hyperparameters-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Finding hyperparameters</a></span></li><li><span><a href=\"#Summary:\" data-toc-modified-id=\"Summary:-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Summary:</a></span></li><li><span><a href=\"#Bonus:-GridSearchCV\" data-toc-modified-id=\"Bonus:-GridSearchCV-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Bonus: GridSearchCV</a></span></li><li><span><a href=\"#Another-example-using-chatGPT\" data-toc-modified-id=\"Another-example-using-chatGPT-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Another example using chatGPT</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Astroinformatics (AS4501), University of Chile**\n",
    "\n",
    "Notebook 1\n",
    "\n",
    "Francisco Förster Burón, CMM-U.Chile / MAS\n",
    "\n",
    "\n",
    "This notebook can be better explored using the Table of Contents extension, see this [link](https://queirozf.com/entries/jupyter-notebook-extensions-examples-and-reference#install-extensions)\n",
    "\n",
    "Please ask questions in U-Cursos forum. If you cannot ask there, you can contact me at francisco.forster@gmail.com and I will post your question and answer in the forum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">Introduction to supervised machine learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T20:05:31.734737Z",
     "start_time": "2020-10-11T20:05:31.730710Z"
    }
   },
   "source": [
    "Extend the width of the notebook (you can change the percentage to adapt to your own screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T18:33:29.823287Z",
     "start_time": "2023-04-10T18:33:29.818042Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:75% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astronomical data follows Moore's law, not growth of telescopes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/data2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New surveys are producing huge data volumes, Vera C. Rubin Obs. Legacy Survey of Space and Time (LSST) will completely change the landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-11T23:17:17.121386Z",
     "start_time": "2020-10-11T23:17:17.006051Z"
    }
   },
   "source": [
    "![](images/data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need machine learning for automated classification, regression or clustering problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/MLtypes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics: overfitting, underfitting and the bias-variance trade-off\n",
    "\n",
    "\n",
    "Two important ideas in machine learning are **overfitting** and **underfitting**.\n",
    "\n",
    "If a model represents our data too accurately, it may not generalize well to unobserved data.\n",
    "\n",
    "A popular solution to reduce overfitting  consists of adding structure to the model through **regularization**. This favors simpler models through training inspired by **Occam's razor**.\n",
    "\n",
    "## Bias\n",
    "\n",
    "It quantifies the precision of the model accross the training sets.\n",
    "\n",
    "## Variance \n",
    "\n",
    "It quantifies how sensitive the model is to small changes in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/biasvariance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complexity, accuracy, robustness\n",
    "\n",
    "In general, we want precise and robust models. \n",
    "\n",
    "**Simpler models tend to be less accurate, but more robust.**\n",
    "\n",
    "**More complex models tend to be more accurate, but less robust.**\n",
    "\n",
    "This tension is usually expressed as the **bias-variance trade-off** which is central to machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\n",
    "No model performs uniformly better than the others. One model may perform better in one data set and badly on another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T00:15:59.413397Z",
     "start_time": "2020-09-20T00:15:59.407175Z"
    }
   },
   "source": [
    "## Predictive or **supervised learning**:\n",
    "\n",
    "Learn a mapping from inputs ${\\bf x}$ to outputs $y$, given a **labeled** set of input-output pairs \n",
    "$D=\\lbrace{({\\bf x_i}, y_i)\\rbrace}_{i=1}^N$.\n",
    "\n",
    "$D$ is called the **training set**.\n",
    "  \n",
    "Each training input ${\\bf x_i}$ is a vector of dimension $M$, with numbers called **features**, **attributes** or **covariates**. They are usually stored in a $N \\times M$ **design matrix** ${\\bf X}$.\n",
    "    \n",
    "### When $y$ is **categorical** the problem is known as **classification**.\n",
    "    \n",
    "### When $y$ is **real--valued** the problem is known as **regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example training set: the iris data set\n",
    "\n",
    "![title](images/iris.png)\n",
    "\n",
    "![title](images/irises.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T19:02:40.484602Z",
     "start_time": "2023-04-10T19:02:40.474866Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#%matplotlib inline\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "dfIris = sns.load_dataset(\"iris\")\n",
    "print(\"Design matrix shape:\", dfIris.shape)\n",
    "print(\"Design matrix columns:\", dfIris.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T19:03:10.327690Z",
     "start_time": "2023-04-10T19:03:10.320538Z"
    }
   },
   "outputs": [],
   "source": [
    "dfIris.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T19:03:17.768926Z",
     "start_time": "2023-04-10T19:03:17.763101Z"
    }
   },
   "outputs": [],
   "source": [
    "dfIris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T19:03:35.399256Z",
     "start_time": "2023-04-10T19:03:35.384952Z"
    }
   },
   "outputs": [],
   "source": [
    "dfIris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T19:06:15.398881Z",
     "start_time": "2023-04-10T19:06:13.647095Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dfIris, hue=\"species\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Descriptive or **unsupervised learning**\n",
    "\n",
    "Only inputs are given: $D=\\lbrace{{\\bf x_i}\\rbrace}_{i=1}^N$\n",
    "    \n",
    "The goal is to find interesting patterns, which is sometimes called **knowledge discovery**\n",
    "  \n",
    "The problem is not always well defined: not clear what kind of pattern to look, no obvious metric to use (unlike supervised learning).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reinforcement learning\n",
    "\n",
    "Mixed between supervised and unsupervised. Only occasional reward or punishement signals are given (e.g. baby learning to walk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised classification loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common loss function is the **zero-one** loss function:\n",
    "\n",
    "$L(y, \\hat y) = \\delta(y \\ne \\hat y)$\n",
    "\n",
    "where $\\hat y$ is the best guess value of $y$\n",
    "\n",
    "The **classification risk** of a model is the expectation value of the loss:\n",
    "\n",
    "$E[L(y, \\hat y)] = p(y \\ne \\hat y)$\n",
    "\n",
    "For the zero-one loss function the risk is equal to the **misclassification rate** or **error rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "$\\Large \\rm accuracy = \\frac{\\#\\ correct\\ labels}{total}$\n",
    "\n",
    "Note that this is one minus the classification risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of errors\n",
    "\n",
    "Accuracy and classification risk are not necessarily good diagnostics of the quality of a model. \n",
    "\n",
    "It is better to distinguish between two types of errors:\n",
    "\n",
    "1. Assigning the label 1 to an object whose true class is 0 (a **false positive**)\n",
    "\n",
    "2. Assigning the label 0 to an object whose true class is 1 (a **false negative**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/TypeIvsII.png)\n",
    "\n",
    "From [The Essential Guide to Effect Sizes: Statistical Power, Meta-Analysis, and the Interpretation of Research Results](https://www.amazon.com/-/es/Paul-D-Ellis/dp/0521142466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:01:48.291516Z",
     "start_time": "2023-04-10T16:01:48.287889Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"900\" height=\"500\" src=\"https://www.youtube.com/embed/8YWl7tDGUPA\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completeness and contamination\n",
    "\n",
    "$\\Large \\rm completeness\\ =\\ \\frac{true~ positives}{true~ positives~ +~ false~ negatives}$\n",
    "\n",
    "$\\Large \\rm contamination\\ =\\ \\frac{false~ positives}{true~ positives~ +~ false~ positives}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall and precision\n",
    "\n",
    "In the machine learning community, the completeness and 1 - contamination are called **recall** and **precision**, respectively.\n",
    "\n",
    "$\\Large \\rm recall\\ =\\ completeness\\ =\\ \\frac{true~ positives}{true~ positives~ +~ false~ negatives}$\n",
    "\n",
    "$\\Large \\rm precision\\ = 1 - contamination = \\ \\frac{true~ positives}{true~ positives~ +~ false~ positives}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True positive rate (TPR) and false positive rate (FPR)\n",
    "\n",
    "\n",
    "$\\Large \\rm TPR\\ =\\ recall\\ =\\ completeness\\ =\\ \\frac{true~ positives}{true~ positives~ +~ false~ negatives}$\n",
    "\n",
    "$\\Large \\rm FPR\\ = \\ \\frac{false~ positives}{false~ positives~ +~ true~ negatives}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Precisionrecall.svg.png)\n",
    "\n",
    "Source: Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with the accuracy \n",
    "\n",
    "To show why accuracy is not a very useful statistic let's consider the following example.\n",
    "\n",
    "e.g. \n",
    "\n",
    "**A model to predict whether a person is from a given country (with a population of 37 million people)**\n",
    "\n",
    "*Simple (and wrong) model*: considering that the world population is 7.5 billion people, predict that a person is from that country with a probability 37/7500.\n",
    "\n",
    "correct labels = $(7,500,000,000 - 37,000,000) * (1 - 37/7500) + 37,000,000 * 37/7500 = 7,426,365,067$\n",
    "\n",
    "$\\Large \\rm accuracy = \\frac{7,426,365,067}{7,500,000,000} = 0.99$\n",
    "\n",
    "\n",
    "Our classifier is 99% accurate, but it is clearly too simplistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and recall are better\n",
    "\n",
    "Let's try precision and recall instead.\n",
    "\n",
    "True positives: $37,000,000 * 37/7500 = 182,533$\n",
    "\n",
    "False positives: $(7,500,000,000 - 37,000,000) * 37/7500 = 36,817,467$\n",
    "\n",
    "False negatives: $37,000,000 * (1 - 37/7500) = 36,817,467$\n",
    "\n",
    "$\\Large \\rm recall = \\frac{182,533}{182,533 + 36,817,467} = 0.005$\n",
    "\n",
    "$\\Large \\rm precision = \\frac{182,533}{182,533 + 36,817,467} = 0.005$\n",
    "\n",
    "Our classifier has only 0.5% recall and precision!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 score\n",
    "\n",
    "A simple statistic which takes into account both precision and recall is the  **$\\rm \\bf F_1$ score**, which is twice their harmonic mean.\n",
    "\n",
    "\n",
    "$\\Large \\rm F_1 = 2\\ \\frac{1}{\\frac{1}{precision}\\ +\\ \\frac{1}{recall}} = 2\\ \\frac{precision\\ \\times\\ recall}{precision\\ +\\ recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F$_\\beta$ score\n",
    "\n",
    "To give more or less weight to recall vs precision, the $F_\\beta$ score is used:\n",
    "\n",
    "$\\Large \\rm F_\\beta = (1 + \\beta^2) \\frac{precision\\ \\times\\ recall}{\\beta^2\\ precision\\ +\\ recall}$ \n",
    "\n",
    "$F_\\beta$ was derived so that it measures the effectiveness of retrieval with respect to a user who attaches **$\\beta$ times as much importance to recall as precision**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro vs micro averages\n",
    "\n",
    "When evaluating the different diagnostics in a multiclass problem one can choose to do macro or micro averages\n",
    "\n",
    "**Macro averaging**\n",
    "\n",
    "    Compute diagnostics for every class. Take average of the class diagnostics \n",
    "    \n",
    "\n",
    "**Micro averaging**\n",
    "\n",
    "    Consider all true positives, false positives, etc.. without making a distinction between classes\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g.\n",
    "\n",
    "| Label | TP | FP | FN | Precision | Recall |\n",
    "| - | - | - | - | - | - |\n",
    "| c1 | 3 | 2 | 7 | 0.6 | 0.3 |\n",
    "| c2 | 1 | 7 | 9 | 0.12 | 0.1 |\n",
    "| c3 | 2 | 5 | 6 | 0.29 | 0.25 |\n",
    "| Total | 6 | 14 | 22 | | | \n",
    "| Macro averaged | | | | 0.34 | 0.22 |\n",
    "| Micro averaged | | | | 0.3 | 0.21 |\n",
    "\n",
    "\n",
    "$\\Large \\rm Macro_{precision} = \\frac{1}{3} \\times \\biggl( \\frac{3}{3 + 2} + \\frac{1}{1 + 7} + \\frac{2}{2 + 5} \\biggr) = 0.34$ \n",
    "\n",
    "$\\Large \\rm Micro_{precision} = \\frac{6}{6 + 14} = 0.3$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Also known as error matrix.\n",
    "\n",
    "The elements of the matrix correspond to the number (or fraction) of instances of an actual class which were classified as another class.\n",
    "\n",
    "A perfect classifier has the identity as its normalized confusion matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/unnormconfusion.png) ![](images/normconfusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver operating characteristics (ROC) curve\n",
    "\n",
    "The **receiver operating characteristic (ROC)** curve is a visualization of the trade-off between the recall and precision of a classifier as the discrimination threshold is varied.\n",
    "\n",
    "It plots the **true positive rate (TPR)** vs the **false positive rate (FPR)** at various thresholds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/ROC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:01:48.295338Z",
     "start_time": "2023-04-10T16:01:48.292458Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"images/roc_curve.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under the curve (AUC) and Gini coefficient (G1)\n",
    "\n",
    "The AUC is equal to the probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one.\n",
    "\n",
    " * A larger AUC indicates a better classification model\n",
    " * A perfect classifier has AUC = 1\n",
    " * A random classifier has AUC = 0.5 (note that the **no-discrimination line** is the identity) \n",
    " * AUC is related to the **Gini coefficient**, which is the twice the area between the ROC and the no-discrimination line: $\\Large \\rm G_1 = 2 AUC - 1$ \n",
    " ![](images/gini.png)\n",
    "\n",
    "The ROC AUC statistic is normally used to do model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Error Tradeoff (DET) curve\n",
    "\n",
    "An alternative to the ROC curve is the **detection error tradeoff (DET)** curve.\n",
    "\n",
    "The DET curve plots the **false negative rate (missed detections) vs the false positive rate (false alarms)** on non-linearly transformed axis in order to emphasize regions of low FPR and low FNR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/DET.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit learn classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "![](images/sklearn_metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of classifiers\n",
    "\n",
    "A lot of classification models have been proposed. Some of them are:\n",
    "\n",
    "* Support Vector Machines (SVM)\n",
    "* Artificial Neural Networks\n",
    "* Decision Trees\n",
    "* Gaussian Mixture Models\n",
    "* Ensembles (multiple models)\n",
    "* Boosting (set of weak classifiers)\n",
    "\n",
    "We will discuss them in the following classes, we will use them as black boxed for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/SVM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-20T00:43:03.304640Z",
     "start_time": "2020-09-20T00:43:03.187937Z"
    }
   },
   "source": [
    "![](images/trees.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/ANN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/GMM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T19:47:23.879398Z",
     "start_time": "2023-04-10T19:47:23.873675Z"
    }
   },
   "outputs": [],
   "source": [
    "HTML('<iframe width=\"900\" height=\"500\" src=\"https://www.youtube.com/embed/9NrALgHFwTo\" frameborder=\"0\" allowfullscreen></iframe>')\n",
    "#HTML('<iframe width=\"900\" height=\"500\" src=\"https://www.youtube.com/embed/8YWl7tDGUPA\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This video is an illustration of Cover's theorem, which states that a nonlinear classification problem can be converted to a linear classification problem by mapping the input vectors from the input space to a higher dimensional feature space. In this example, a 2-dimensional classification is mapped into 3-dimensions using a 2-dimensional Gaussian function.to augment the input vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scikit-Learn API\n",
    "\n",
    "* Base object is the estimator\n",
    "* Any object that learns from data\n",
    "    * Classification, regression, clustering, or transformer \n",
    "\n",
    "\n",
    "* parameters passed to estimator\n",
    "\n",
    "```python\n",
    "    estimator = Estimator(*args, **kwargs)\n",
    "```\n",
    "\n",
    "* `fit` method provided\n",
    "\n",
    "```python\n",
    "    estimator.fit(X, y)\n",
    "```\n",
    "    \n",
    "* Computed parameters have an underscore appended\n",
    "\n",
    "```python\n",
    "    estimator.coef_\n",
    "```\n",
    "\n",
    "* Method to predict probability\n",
    "\n",
    "```python\n",
    "    estimator.predict_proba(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two class classification examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two classes, one feature classification example\n",
    "\n",
    "We will show a simple example of a classifier between two classes which have only one feature.\n",
    "\n",
    "We use sklearn.datasets.make_classification to generate some data, sklearn.model_selection.train_test_split to split the data into training and test, sklearn.svm.SVC as the classification model, sklearn.metrics.roc_curve to generate the ROC curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:35:25.053577Z",
     "start_time": "2023-04-17T19:35:24.696246Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# data sets\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# for splitting data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Support vector machine, C-support vector classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# metrics \n",
    "from sklearn import metrics\n",
    "\n",
    "# generate data and classes\n",
    "X, y = make_classification(n_samples = 100, n_classes = 2, n_features=1, n_redundant=0, n_informative=1,\n",
    "                           random_state=40, n_clusters_per_class=1)\n",
    "\n",
    "# histograms of the two classes\n",
    "fig, ax = plt.subplots(ncols = 2, figsize = (15, 6))\n",
    "ax[0].hist(X[y == 0], color = 'r', alpha = 0.5, label = \"Class 0\", density = True);\n",
    "ax[0].hist(X[y == 1], color = 'b', alpha = 0.5, label = \"Class 1\", density = True);\n",
    "\n",
    "# split the data and plot\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=30)\n",
    "ax[1].hist(X_train[y_train == 0], color = 'r', alpha = 0.5, label = \"Class 0 training\");\n",
    "ax[1].hist(X_train[y_train == 1], color = 'b', alpha = 0.5, label = \"Class 1 training\");\n",
    "ax[1].hist(X_test[y_test == 0], color = 'r', histtype = 'step', lw = 3, label = \"Class 0 test\", bins=20);\n",
    "ax[1].hist(X_test[y_test == 1], color = 'b', histtype = 'step', lw = 3, label = \"Class 1 test\", bins=20);\n",
    "\n",
    "# train a c-support vector classifier and plot the probability\n",
    "clf = SVC(kernel=\"linear\", C=0.01, probability=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_test_pred = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xs = np.linspace(min(X), max(X), 100)\n",
    "xs = xs\n",
    "probs = clf.predict_proba(xs)[:, 1]\n",
    "ax[0].plot(xs, probs, label = \"Probability of class 1\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:01:48.913731Z",
     "start_time": "2023-04-10T16:01:48.802727Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the ROC curve\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_test, y_test_pred, pos_label=1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"AUC: %.3f\" % metrics.roc_auc_score(y_test, y_test_pred))\n",
    "ax.plot(fpr, tpr)\n",
    "sc = ax.scatter(fpr, tpr, lw = 1, c = thresh, cmap = matplotlib.cm.jet)\n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label('Prob. threshold')\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Precisionrecall.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:01:49.035756Z",
     "start_time": "2023-04-10T16:01:48.915381Z"
    }
   },
   "outputs": [],
   "source": [
    "# get F1 score for different probability thresholds\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.linspace(0, 1, 100)\n",
    "f1scores = list(map(lambda prob: metrics.f1_score(y_test, y_test_pred >= prob), xs))\n",
    "ax.plot(xs, f1scores)\n",
    "ax.set_xlabel('Probability threshold', fontsize = 16)\n",
    "ax.set_ylabel('F1-score', fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for plotting the confusion matrix\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:02:37.027667Z",
     "start_time": "2023-04-17T19:02:37.015020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to pretty print the confusion matrix\n",
    "\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:01:49.258650Z",
     "start_time": "2023-04-10T16:01:49.043138Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots()\n",
    "plot_confusion_matrix(metrics.confusion_matrix(y_test, y_test_pred >= 0.5), range(2))\n",
    "plt.subplots()\n",
    "plot_confusion_matrix(metrics.confusion_matrix(y_test, y_test_pred >= 0.5), range(2), normalize=True, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two class classification examples from sklearn\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "Comparison between different classifiers on three different simulated datasets: \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\", \"Naive Bayes\" and \"QDA\".\n",
    "\n",
    "![](images/sklearn_classification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add ROC plots for each of the classifiers above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T18:48:52.740544Z",
     "start_time": "2023-04-17T18:48:46.828421Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# for splitting data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# standardize features removing the mean and scaling to unit variance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# data sets\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "# multilayer perceptron classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# K nearest neighbors classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Support vector machine, C-support vector classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Gaussian process classifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "# radial basis function kernel (squared exponential kernel)\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# Decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Ensemble classifiers: Random forest and AdaBoost\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Quadratic Discriminant Analysis classifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# different classifiers\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, probability = True),\n",
    "    SVC(gamma=2, C=1, probability = True),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "\n",
    "# linearly separable datatest\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=1, n_clusters_per_class=1)\n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "# all different datasets\n",
    "datasets = [make_moons(noise=0.3, random_state=0),\n",
    "            make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "            linearly_separable\n",
    "            ]\n",
    "\n",
    "figure = plt.figure(figsize=(27, 15))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # test_size is 40% of the data\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, y, test_size=.4, random_state=42)\n",
    "                \n",
    "    # create grid to evaluate classifiers\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(2 * len(datasets), len(classifiers) + 1, i + ds_cnt * (len(classifiers) + 1))\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(2 * len(datasets), len(classifiers) + 1, i + ds_cnt * (len(classifiers) + 1))\n",
    "        \n",
    "        # fit the model using the training set\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # compute the mean accuracy of the classifier\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "                   edgecolors='k')\n",
    "\n",
    "        # plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   edgecolors='k', alpha=0.6)\n",
    "\n",
    "        # set limits\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        \n",
    "        # remove ticks\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        \n",
    "        # write title only for the first data set for each classifier\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "            \n",
    "        # plot the accuracy score\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        \n",
    "        # compute ROC curve\n",
    "        y_test_pred = clf.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred, pos_label=1)\n",
    "        auc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "        acc = metrics.accuracy_score(y_test, y_test_pred >= 0.5)\n",
    "        f1 = metrics.f1_score(y_test, y_test_pred >= 0.5)\n",
    "        ax = plt.subplot(2 * len(datasets), len(classifiers) + 1, i + (ds_cnt + 1) * (len(classifiers) + 1))\n",
    "        ax.set_xlim(-.05, 1.05)\n",
    "        ax.set_ylim(-.05, 1.05)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.text(0.95, 0.3, \"Acc: %.2f\" % acc, ha = 'right')\n",
    "        ax.text(0.95, 0.2, \"F1-score: %.2f\" % f1, ha = 'right')\n",
    "        ax.text(0.95, 0.1, \"AUC: %.2f\" % auc, ha = 'right')\n",
    "        ax.plot(fpr, tpr, lw = 5)\n",
    "        idx = np.argmin(np.abs(thresholds - 0.5))\n",
    "        ax.scatter(fpr[idx], tpr[idx], marker = 'o', c = 'r')\n",
    "\n",
    "        # counter \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some classifiers are inherently multiclass:\n",
    "\n",
    "* Naive Bayes\n",
    "\n",
    "* Logistic Regression\n",
    "\n",
    "* K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other classifiers are binary:\n",
    "\n",
    "* support vector machine\n",
    "\n",
    "* perceptron\n",
    "\n",
    "* boosting\n",
    "\n",
    "These classifiers requiere modifications to become multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary to multiclass\n",
    "\n",
    "In order to make a binary classifier multiclass we can do different things:\n",
    "\n",
    "Let us assume there are k classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs the rest\n",
    "\n",
    "Build k classifiers which classify one class vs all the others. \n",
    "\n",
    "   * It will fail if any classifier fails!\n",
    "   \n",
    "   ![](images/onevsall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs one\n",
    "\n",
    "Build k (k - 1) / 2 classifiers using all possible pairs of classes. Make the classifiers vote to decide the class.\n",
    "\n",
    "   * Training each class only uses elements from pairs of classes -> training can be faster\n",
    "   \n",
    "   * Evaluation can be slower since we need to run more models\n",
    "   \n",
    "   * This is used by **sklearn for SVM classifiers SVC and NuSVC**\n",
    "   \n",
    "   ![](images/allpairs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error correcting output codes\n",
    "\n",
    "Use sequences of ones or zeros to represent each class (codewords). Train as many classifiers as the number of bits in the codewords. Apply each classifier to the corresponding bit (output will be binary) and select the class with the closest codeword.\n",
    "\n",
    "    * Selecting codewords with more bits than classes allows for some redundancy, hence the \"Error Correcting\" name\n",
    "    \n",
    "    * Example of ten classes and codewords of 15 bits.  In this case 15 binary classifiers are trained.\n",
    "    \n",
    "![](images/ECOC.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of multiclass classification\n",
    "\n",
    "### Multiclass classification on the NIST dataset\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T18:58:51.117115Z",
     "start_time": "2023-04-17T18:58:50.790110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits\n",
    "# images are in digits.images and their associated numbers in digits.target\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:8]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T18:59:33.023061Z",
     "start_time": "2023-04-17T18:59:33.015247Z"
    }
   },
   "outputs": [],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:01:13.866204Z",
     "start_time": "2023-04-17T19:01:13.700305Z"
    }
   },
   "outputs": [],
   "source": [
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:01:53.484353Z",
     "start_time": "2023-04-10T16:01:53.481402Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:02:15.489095Z",
     "start_time": "2023-04-17T19:02:15.056101Z"
    }
   },
   "outputs": [],
   "source": [
    "# now we confirm our predicted images\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:8]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:02:46.064458Z",
     "start_time": "2023-04-17T19:02:45.547379Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plt.figure(figsize = (14, 10))\n",
    "plot_confusion_matrix(metrics.confusion_matrix(expected, predicted), classes=range(10), normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification on the iris dataset\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:04:54.254458Z",
     "start_time": "2023-04-17T19:04:54.245423Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:04:58.099448Z",
     "start_time": "2023-04-17T19:04:56.790488Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "iris = datasets.load_iris()\n",
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 0.1  # SVM regularization parameter\n",
    "models = (svm.SVC(kernel='linear', C=C),\n",
    "          svm.LinearSVC(C=C),\n",
    "          svm.SVC(kernel='rbf', gamma=0.7, C=C),\n",
    "          svm.SVC(kernel='poly', degree=3, C=C))\n",
    "models = (clf.fit(X, y) for clf in models)\n",
    "\n",
    "# plot titles\n",
    "titles = ('SVC with linear kernel',\n",
    "          'LinearSVC (linear kernel)',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel')\n",
    "\n",
    "# 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2, figsize = (12, 10))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = X[:, 0], X[:, 1]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    plot_contours(ax, clf, xx, yy,\n",
    "                  cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xlabel('Sepal length')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, validation and test sets\n",
    "\n",
    "It is clear that the separattion between training and test sets is needed in order to avoid overfitting.\n",
    "\n",
    "However, when optimizing the **hyperparameters** of a classification model one must use some test set as diagnostic. \n",
    "\n",
    "This means that the hyperparameters can be **overfitted to the test set**.\n",
    "\n",
    "In order to avoid this problem an intermediate test set is created: the **validation** set.\n",
    "\n",
    "Thus, in general one will need **training**, **validation** and **test** sets to solve the classification problem, which has the disadvantage of reducing the set sizes even further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "A solution to the previous problem is called **cross--validation (CV)**, which is a family of set splitting strategies.\n",
    "\n",
    "* The simplest is called **k-fold CV**: \n",
    "    \n",
    "    A test set is held out for final evaluation. The training set is split into k smaller sets.\n",
    "    \n",
    "    A model is trained using k-1 of the folds as training data.\n",
    "    \n",
    "    The resulting model is evaluated on the remaining part of the data.\n",
    "    \n",
    "    The performance measure reported by k-fold CV is the average of the previous values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations on k-fold\n",
    "\n",
    "* **Repeated k-fold**:\n",
    "\n",
    "    Repeat k-fold CV n times, producing different folds each time\n",
    "    \n",
    "\n",
    "* **Leave One Out (LOO)**:\n",
    "\n",
    "    Each learning is created by taking all samples except one\n",
    "    \n",
    "    For n samples, we have n different training sets\n",
    "    \n",
    "    As a general rule, 5 or 10-fold CV is preferred\n",
    "    \n",
    "\n",
    "* **Leave P out (LPO)**:\n",
    "\n",
    "    Similar to LOO, but removing p samples\n",
    "    \n",
    "\n",
    "* Random permutations and split (**shuffle & split**):\n",
    "\n",
    "    A user defined number of independents train / validation dataset splits. Each time samples are shuffled and then split.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeated k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:17:52.788958Z",
     "start_time": "2023-04-17T19:17:52.237730Z"
    }
   },
   "outputs": [],
   "source": [
    "# K-fold with 4 split\n",
    "np.random.seed(2)\n",
    "X = np.random.random((9, 2))\n",
    "\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, ShuffleSplit, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "n_splits = 4\n",
    "\n",
    "# Kfold\n",
    "fig, ax = plt.subplots(ncols = n_splits, figsize = (n_splits * 5, 5))\n",
    "kf = KFold(n_splits=n_splits)\n",
    "for idx, traintest in enumerate(kf.split(X)):\n",
    "    train, test = traintest\n",
    "    ax[idx].scatter(X[train][:, 0], X[train][:, 1], c = 'r', s = 100, label = 'training')\n",
    "    ax[idx].scatter(X[test][:, 0], X[test][:, 1], c = 'b', s = 100, label = 'validation')\n",
    "    ax[idx].legend(frameon=True, shadow=True);\n",
    "\n",
    "# note that any point is blue once and only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:19:19.556535Z",
     "start_time": "2023-04-17T19:19:18.541768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Leave one out\n",
    "\n",
    "fig, ax = plt.subplots(ncols = len(X), figsize = (len(X) * 5, 5))\n",
    "kf = LeaveOneOut()\n",
    "for idx, traintest in enumerate(kf.split(X)):\n",
    "    train, test = traintest\n",
    "    ax[idx].scatter(X[train][:, 0], X[train][:, 1], c = 'r', s = 200, label = 'training')\n",
    "    ax[idx].scatter(X[test][:, 0], X[test][:, 1], c = 'b', s = 200, label = 'validation')\n",
    "    ax[idx].legend(frameon=True, shadow=True);\n",
    "\n",
    "\n",
    "# note that only one point is left out each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:20:23.495452Z",
     "start_time": "2023-04-17T19:20:22.976260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle & Split\n",
    "\n",
    "fig, ax = plt.subplots(ncols = n_splits, figsize = (n_splits * 5, 5))\n",
    "kf = ShuffleSplit(n_splits = n_splits, test_size = 0.25)\n",
    "for idx, traintest in enumerate(kf.split(X)):\n",
    "    train, test = traintest\n",
    "    ax[idx].scatter(X[train][:, 0], X[train][:, 1], c = 'r', s = 100, label = 'training')\n",
    "    ax[idx].scatter(X[test][:, 0], X[test][:, 1], c = 'b', s = 100, label = 'validation')\n",
    "    ax[idx].legend(frameon=True, shadow=True);\n",
    "\n",
    "\n",
    "# note that some points can be blue more than once and some are red always"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variations on k-fold that balance (stratify) class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-fold CV\n",
    "Each set contains approximately the same percentage of samples of each target class as the complete set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:22:32.390732Z",
     "start_time": "2023-04-17T19:22:32.384083Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "X = np.random.random((20, 2))\n",
    "y = np.random.random(20) > 0.3 # 70% circles + 30% stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we show a normal k fold for comparison with two classes.\n",
    "\n",
    "We will assume two classes: stars and circles. We will show elements in the training set in red, and elements in the validation set in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:22:40.502736Z",
     "start_time": "2023-04-17T19:22:39.716690Z"
    }
   },
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "fig, ax = plt.subplots(ncols = n_splits, figsize = (n_splits * 5, 5))\n",
    "kf = KFold(n_splits = n_splits)\n",
    "for idx, traintest in enumerate(kf.split(X)):\n",
    "    train, test = traintest\n",
    "    ax[idx].scatter(X[train][~y[train]][:, 0], X[train][~y[train]][:, 1], marker = '*', s = 200, c = 'r', label = 'training class 0')\n",
    "    ax[idx].scatter(X[test][~y[test]][:, 0], X[test][~y[test]][:, 1], marker = '*', s = 200, c = 'b', label = 'validation class 0')\n",
    "    ax[idx].scatter(X[train][y[train]][:, 0], X[train][y[train]][:, 1], c = 'r', s = 100, label = 'training class 1')\n",
    "    ax[idx].scatter(X[test][y[test]][:, 0], X[test][y[test]][:, 1], c = 'b', s = 100, label = 'validation class 1')\n",
    "    ax[idx].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in 1st and 2nd splits the validation set does not contain any stars.\n",
    "\n",
    "Let's now try a stratified k fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:23:18.706823Z",
     "start_time": "2023-04-17T19:23:18.105956Z"
    }
   },
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "fig, ax = plt.subplots(ncols = n_splits, figsize = (n_splits * 5, 5))\n",
    "kf = StratifiedKFold(n_splits = n_splits)\n",
    "for idx, traintest in enumerate(kf.split(X, y)):\n",
    "    train, test = traintest\n",
    "    ax[idx].scatter(X[train][~y[train]][:, 0], X[train][~y[train]][:, 1], marker = '*', s = 200, c = 'r', label = 'training class 0')\n",
    "    ax[idx].scatter(X[test][~y[test]][:, 0], X[test][~y[test]][:, 1], marker = '*', s = 200, c = 'b', label = 'validation class 0')\n",
    "    ax[idx].scatter(X[train][y[train]][:, 0], X[train][y[train]][:, 1], c = 'r', s = 100, label = 'training class 1')\n",
    "    ax[idx].scatter(X[test][y[test]][:, 0], X[test][y[test]][:, 1], c = 'b', s = 100, label = 'validation class 1')\n",
    "    ax[idx].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the validation set contains at least one star in each fold, and this star never repeats between folds.\n",
    "\n",
    "Let's now try a stratified shuffle split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:23:59.417792Z",
     "start_time": "2023-04-17T19:23:58.821821Z"
    }
   },
   "outputs": [],
   "source": [
    "n_splits = 4\n",
    "fig, ax = plt.subplots(ncols = n_splits, figsize = (n_splits * 5, 5))\n",
    "kf = StratifiedShuffleSplit(n_splits = n_splits, test_size = 0.25)\n",
    "for idx, traintest in enumerate(kf.split(X, y)):\n",
    "    train, test = traintest\n",
    "    ax[idx].scatter(X[train][~y[train]][:, 0], X[train][~y[train]][:, 1], marker = '*', s = 200, c = 'r', label = 'training class 0')\n",
    "    ax[idx].scatter(X[test][~y[test]][:, 0], X[test][~y[test]][:, 1], marker = '*', s = 200, c = 'b', label = 'validation class 0')\n",
    "    ax[idx].scatter(X[train][y[train]][:, 0], X[train][y[train]][:, 1], c = 'r', s = 100, label = 'training class 1')\n",
    "    ax[idx].scatter(X[test][y[test]][:, 0], X[test][y[test]][:, 1], c = 'b', s = 100, label = 'validation class 1')\n",
    "    ax[idx].legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the validation now contains at least one star each time, and they can be repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbalanced classification\n",
    "\n",
    "Here we illustrate the problem of training with unbalanced classes\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:35:48.509510Z",
     "start_time": "2023-04-17T19:35:48.277585Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's create 40 separable points\n",
    "rng = np.random.RandomState(4)\n",
    "# size of classes with 10:1 ratio\n",
    "n_samples_1 = 1000\n",
    "n_samples_2 = 100\n",
    "ratio = n_samples_1 / n_samples_2\n",
    "# X values \n",
    "X = np.r_[1.5 * rng.randn(n_samples_1, 2),\n",
    "          0.5 * rng.randn(n_samples_2, 2) + [2., 2.]]\n",
    "# classes\n",
    "y = [0] * (n_samples_1) + [1] * (n_samples_2)\n",
    "\n",
    "# fit the model and get the separating hyperplane\n",
    "clf = svm.SVC(kernel='linear')#, C=1.0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# fit the model and get the separating hyperplane weighting the classes by the inverse of their sizes\n",
    "wclf = svm.SVC(kernel='linear', class_weight={1: 10})\n",
    "wclf.fit(X, y)\n",
    "\n",
    "# plot separating hyperplanes and samples\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')\n",
    "plt.legend()\n",
    "\n",
    "# plot the decision functions for both classifiers\n",
    "# ---------\n",
    "\n",
    "# start plot\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "# get the separating hyperplane\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins\n",
    "a = ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.5, linestyles=['-'])\n",
    "\n",
    "# get the separating hyperplane for weighted classes\n",
    "Z = wclf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "# plot decision boundary and margins for weighted classes\n",
    "b = ax.contour(XX, YY, Z, colors='r', levels=[0], alpha=0.5, linestyles=['-'])\n",
    "\n",
    "plt.legend([a.collections[0], b.collections[0]], [\"non weighted\", \"weighted\"],\n",
    "           loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that whether to use weighted training depends on what is our aim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding hyperparameters\n",
    "\n",
    "We will use the previous example of an unbalanced set.\n",
    "\n",
    " * We will first do a Stratified test-training split.\n",
    " * Then we will use StratifiedKFold to build validation sets\n",
    " * We will choose the best hyperparameter C for the previous classifier based on the average AUCs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:35:51.174704Z",
     "start_time": "2023-04-17T19:35:50.995733Z"
    }
   },
   "outputs": [],
   "source": [
    "# extract the test and training sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], marker = 'o', edgecolors = 'k', c = y_train, cmap = matplotlib.cm.Paired, alpha = 0.8, label = 'Train')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], marker = '*', edgecolors = 'k', s = 200, c = y_test, cmap = matplotlib.cm.Paired, alpha = 0.8, label= 'Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:38:34.166820Z",
     "start_time": "2023-04-17T19:38:20.104670Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Cs = np.logspace(-4, 1, 20)\n",
    "AUCs = np.zeros_like(Cs)\n",
    "\n",
    "# vary the error penaly parameter C between 0.1 and 10 in a logarithmic grid\n",
    "for idx, C in enumerate(Cs):\n",
    "    print(\"C: %f\" % C, end = '\\r')\n",
    "\n",
    "    # weighted classifier\n",
    "    wclf = svm.SVC(C = C, kernel='linear', probability = True, class_weight={1: 10})\n",
    "    \n",
    "    # do 10-fold stratified splits\n",
    "    n_splits = 10\n",
    "    kf = StratifiedKFold(n_splits = n_splits)\n",
    "\n",
    "    # train with the resulting training sets\n",
    "    for train, validation in kf.split(X_train, y_train):\n",
    "    \n",
    "        wclf.fit(X_train[train], y_train[train])\n",
    "        y_validation_pred = wclf.predict_proba(X_train[validation])[:, 1]\n",
    "        AUCs[idx] += metrics.roc_auc_score(y_train[validation], y_validation_pred)\n",
    "        \n",
    "    AUCs[idx] /= n_splits\n",
    "    \n",
    "ax.plot(Cs, AUCs, label = 'Validation')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(\"C\")\n",
    "ax.set_ylabel(\"AUC\")\n",
    "\n",
    "# choose best C value\n",
    "idxbest = np.argmax(AUCs)\n",
    "wclf = svm.SVC(C = Cs[idxbest], kernel='linear', probability = True, class_weight={1: 10})\n",
    "wclf.fit(X_train, y_train)\n",
    "y_test_pred = wclf.predict_proba(X_test)[:, 1]\n",
    "finalAUC = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Final AUC in test set: %.4f\" % finalAUC)\n",
    "\n",
    "# check what was the AUCs for different Cs in the test set\n",
    "AUCs_test = np.zeros_like(AUCs)\n",
    "for idx, C in enumerate(Cs):\n",
    "    wclf = svm.SVC(C = C, kernel='linear', probability = True, class_weight={1: 10})\n",
    "    wclf.fit(X_train, y_train)\n",
    "    y_test_pred = wclf.predict_proba(X_test)[:, 1]\n",
    "    AUCs_test[idx] = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "\n",
    "ax.plot(Cs, AUCs_test, label = 'Test')\n",
    "ax.axvline(Cs[idxbest], c = 'gray', label = 'Best C in validation')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this case the regularization parameter does not affect significantly the result. Also, note that the best value in the validation test does not necessarily consistent with the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "* Different diagnostics to measure the quality of a classifier beyond its accuracy.\n",
    "\n",
    "* Recall and precision and variations the key diagnostics, F1 and F$_\\beta$ harmonic mean averages (incl. weights).\n",
    "\n",
    "* Macro and micro averages can be used for all diagnostics\n",
    "\n",
    "* ROC and DET curves allows visualizing trade--off between false positives and false negatives\n",
    "\n",
    "* Area under the curve measures overall quality.\n",
    "\n",
    "* Training, validation and test sets important to allow model selection without overfitting (knowledge leaking)\n",
    "\n",
    "* Different techniques to avoid very small validation and test sets: variations on K-fold cross-validation (stratified important for unbalanced sets)\n",
    "\n",
    "* Training with unbalanced sets may require weighting the sample\n",
    "\n",
    "* Remember that you can train with the full dataset after all the previous tests in order to build a classifier which will be used in some other data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:42:10.135237Z",
     "start_time": "2023-04-17T19:42:10.061370Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Loading the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:42:12.589620Z",
     "start_time": "2023-04-17T19:42:12.585011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T19:42:19.494794Z",
     "start_time": "2023-04-17T19:42:14.941804Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set (%s):\" % score)\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize = (14, 10))\n",
    "    plot_confusion_matrix(metrics.confusion_matrix(y_true, y_pred), classes=range(10), normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another example using chatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you provide an example code in python where you train a classifier using SVM and fine tune the hyper parameters using cross validation using grid search? I would like you to work on the following steps:\n",
    "1. load the breast cancer dataset\n",
    "2. scale the dataset\n",
    "3. show me a histogram of the distribution of classes\n",
    "4. split the dataset in training and test\n",
    "5. use a support vector machine and grid search to find the best hyperparameters\n",
    "6. show me the dependency of the f1-score with the hyperparameters\n",
    "7. plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
